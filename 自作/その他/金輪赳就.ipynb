{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テーマ:手書き数字のデータセットを使用し、ディープラーニングにより画像データの分類を行う（段階的に改善していく）\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-macosx_10_11_x86_64.whl (195.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 195.7 MB 159 kB/s  eta 0:00:01  |▏                               | 1.1 MB 6.1 MB/s eta 0:00:32     |███▏                            | 19.7 MB 14.5 MB/s eta 0:00:13     |████▌                           | 27.4 MB 14.5 MB/s eta 0:00:12     |████████                        | 48.6 MB 8.9 MB/s eta 0:00:17     |██████████                      | 61.8 MB 8.9 MB/s eta 0:00:16     |████████████▎                   | 75.2 MB 17.5 MB/s eta 0:00:07     |████████████▊                   | 77.6 MB 17.5 MB/s eta 0:00:07     |████████████████▌               | 100.6 MB 13.9 MB/s eta 0:00:07     |██████████████████▉             | 115.3 MB 13.9 MB/s eta 0:00:06     |████████████████████▍           | 124.5 MB 27.3 MB/s eta 0:00:03     |██████████████████████▌         | 137.3 MB 27.3 MB/s eta 0:00:03     |██████████████████████▊         | 138.6 MB 27.3 MB/s eta 0:00:03     |████████████████████████████▌   | 174.4 MB 17.5 MB/s eta 0:00:02     |██████████████████████████████▉ | 188.8 MB 17.5 MB/s eta 0:00:01     |███████████████████████████████▎| 191.5 MB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 28.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-macosx_10_10_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 33.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 34.0 MB/s eta 0:00:01     |████████████████████            | 3.7 MB 34.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 5.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 23.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 33.7 MB/s eta 0:00:01     |███████████▎                    | 276 kB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 37.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 22.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=7f983a6ba4d2c1ccf5528705766b646c543778695ddad14c24ec8ac2579b627c\n",
      "  Stored in directory: /Users/macuser/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19552 sha256=e7760cd2875a8c0cd43ed223c6d3ea7e6fdcbf7d7ad15b2ff9118035dd304177\n",
      "  Stored in directory: /Users/macuser/Library/Caches/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: absl-py, flatbuffers, gast, h5py, termcolor, wrapt, astunparse, grpcio, keras-preprocessing, tensorboard-plugin-wit, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, protobuf, markdown, tensorboard, google-pasta, opt-einsum, keras-nightly, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.32.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_mnist(flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# 形状の確認\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# 各サンプルは、(一次元に変換しているが、)(28, 28)の形状であることが分かる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー変数への展開\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 再び形状の確認\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# まずは、全結合層のみで構成したモデルで分類を行ってみる\n",
    "\n",
    "# 説明変数の例\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train= (42000, 10) , X_train= (42000, 784)\n",
      "Y_valid= (18000, 10) , X_valid= (18000, 784)\n",
      "Y_test= (10000, 10) , X_test= (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 形状を確認\n",
    "print(\"Y_train=\", Y_train.shape, \", X_train=\", X_train.shape)\n",
    "print(\"Y_valid=\", Y_valid.shape, \", X_valid=\", X_valid.shape)\n",
    "print(\"Y_test=\", Y_test.shape, \", X_test=\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "# 中間層\n",
    "model.add(Dense(64, activation='relu', input_shape=(128,)))\n",
    "model.add(Dense(32, activation='relu', input_shape=(64,)))\n",
    "model.add(Dense(16, activation='relu', input_shape=(32,)))\n",
    "# 出力層\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 111,514\n",
      "Trainable params: 111,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの構造を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.2828 - val_accuracy: 0.9736\n",
      "Epoch 2/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.2925 - val_accuracy: 0.9728\n",
      "Epoch 3/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.3015 - val_accuracy: 0.9724\n",
      "Epoch 4/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 0.2905 - val_accuracy: 0.9738\n",
      "Epoch 5/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.3368 - val_accuracy: 0.9732\n",
      "Epoch 6/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.3245 - val_accuracy: 0.9742\n",
      "Epoch 7/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.3718 - val_accuracy: 0.9716\n",
      "Epoch 8/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.3901 - val_accuracy: 0.9728\n",
      "Epoch 9/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.3619 - val_accuracy: 0.9744\n",
      "Epoch 10/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.3548 - val_accuracy: 0.9735\n",
      "Epoch 11/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.3767 - val_accuracy: 0.9731\n",
      "Epoch 12/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.4042 - val_accuracy: 0.9745\n",
      "Epoch 13/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.4427 - val_accuracy: 0.9721\n",
      "Epoch 14/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.3809 - val_accuracy: 0.9746\n",
      "Epoch 15/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.4190 - val_accuracy: 0.9733\n",
      "Epoch 16/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.4010 - val_accuracy: 0.9728\n",
      "Epoch 17/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.4354 - val_accuracy: 0.9741\n",
      "Epoch 18/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.4885 - val_accuracy: 0.9722\n",
      "Epoch 19/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.4909 - val_accuracy: 0.9726\n",
      "Epoch 20/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.5211 - val_accuracy: 0.9729\n",
      "Epoch 21/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.5086 - val_accuracy: 0.9724\n",
      "Epoch 22/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.4595 - val_accuracy: 0.9726\n",
      "Epoch 23/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.5129 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.4980 - val_accuracy: 0.9750\n",
      "Epoch 25/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.4878 - val_accuracy: 0.9742\n",
      "Epoch 26/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.5475 - val_accuracy: 0.9713\n",
      "Epoch 27/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.4825 - val_accuracy: 0.9742\n",
      "Epoch 28/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.5618 - val_accuracy: 0.9729\n",
      "Epoch 29/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.5220 - val_accuracy: 0.9718\n",
      "Epoch 30/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.5178 - val_accuracy: 0.9742\n",
      "Epoch 31/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.4999 - val_accuracy: 0.9741\n",
      "Epoch 32/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.5267 - val_accuracy: 0.9743\n",
      "Epoch 33/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.5932 - val_accuracy: 0.9715\n",
      "Epoch 34/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.5532 - val_accuracy: 0.9733\n",
      "Epoch 35/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.5866 - val_accuracy: 0.9725\n",
      "Epoch 36/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.5466 - val_accuracy: 0.9721\n",
      "Epoch 37/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.6384 - val_accuracy: 0.9713\n",
      "Epoch 38/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.6679 - val_accuracy: 0.9716\n",
      "Epoch 39/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.6320 - val_accuracy: 0.9739\n",
      "Epoch 40/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.6883 - val_accuracy: 0.9697\n",
      "Epoch 41/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.6635 - val_accuracy: 0.9749\n",
      "Epoch 42/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.6306 - val_accuracy: 0.9727\n",
      "Epoch 43/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0135 - accuracy: 0.9985 - val_loss: 0.6518 - val_accuracy: 0.9747\n",
      "Epoch 44/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.6325 - val_accuracy: 0.9734\n",
      "Epoch 45/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.6128 - val_accuracy: 0.9746\n",
      "Epoch 46/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.6898 - val_accuracy: 0.9733\n",
      "Epoch 47/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.6723 - val_accuracy: 0.9742\n",
      "Epoch 48/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.6528 - val_accuracy: 0.9749\n",
      "Epoch 49/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.6967 - val_accuracy: 0.9739\n",
      "Epoch 50/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.7088 - val_accuracy: 0.9731\n",
      "Epoch 51/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.7508 - val_accuracy: 0.9738\n",
      "Epoch 52/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.6836 - val_accuracy: 0.9739\n",
      "Epoch 53/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.7532 - val_accuracy: 0.9736\n",
      "Epoch 54/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.7391 - val_accuracy: 0.9734\n",
      "Epoch 55/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.8072 - val_accuracy: 0.9727\n",
      "Epoch 56/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.8282 - val_accuracy: 0.9728\n",
      "Epoch 57/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.8462 - val_accuracy: 0.9727\n",
      "Epoch 58/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.8444 - val_accuracy: 0.9695\n",
      "Epoch 59/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.7883 - val_accuracy: 0.9737\n",
      "Epoch 60/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.8215 - val_accuracy: 0.9726\n",
      "Epoch 61/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.7901 - val_accuracy: 0.9744\n",
      "Epoch 62/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.7719 - val_accuracy: 0.9728\n",
      "Epoch 63/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.7592 - val_accuracy: 0.9746\n",
      "Epoch 64/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.7997 - val_accuracy: 0.9747\n",
      "Epoch 65/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.8439 - val_accuracy: 0.9736\n",
      "Epoch 66/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.8168 - val_accuracy: 0.9740\n",
      "Epoch 67/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.8094 - val_accuracy: 0.9747\n",
      "Epoch 68/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.8269 - val_accuracy: 0.9738\n",
      "Epoch 69/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.8995 - val_accuracy: 0.9724\n",
      "Epoch 70/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.8950 - val_accuracy: 0.9739\n",
      "Epoch 71/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.8808 - val_accuracy: 0.9713\n",
      "Epoch 72/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.8807 - val_accuracy: 0.9719\n",
      "Epoch 73/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.8997 - val_accuracy: 0.9732\n",
      "Epoch 74/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.8464 - val_accuracy: 0.9738\n",
      "Epoch 75/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.9888 - val_accuracy: 0.9730\n",
      "Epoch 76/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.9689 - val_accuracy: 0.9731\n",
      "Epoch 77/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.9199 - val_accuracy: 0.9736\n",
      "Epoch 78/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.8743 - val_accuracy: 0.9742\n",
      "Epoch 79/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 0.9140 - val_accuracy: 0.9722\n",
      "Epoch 80/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.8153 - val_accuracy: 0.9734\n",
      "Epoch 81/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.9470 - val_accuracy: 0.9729\n",
      "Epoch 82/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 1.0126 - val_accuracy: 0.9695\n",
      "Epoch 83/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.9306 - val_accuracy: 0.9734\n",
      "Epoch 84/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.9767 - val_accuracy: 0.9734\n",
      "Epoch 85/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.9335 - val_accuracy: 0.9733\n",
      "Epoch 86/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.9703 - val_accuracy: 0.9736\n",
      "Epoch 87/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 1.0250 - val_accuracy: 0.9726\n",
      "Epoch 88/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.9976 - val_accuracy: 0.9722\n",
      "Epoch 89/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 1.0340 - val_accuracy: 0.9723\n",
      "Epoch 90/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 1.0018 - val_accuracy: 0.9733\n",
      "Epoch 91/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 1.0520 - val_accuracy: 0.9740\n",
      "Epoch 92/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 1.0267 - val_accuracy: 0.9729\n",
      "Epoch 93/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.9489 - val_accuracy: 0.9737\n",
      "Epoch 94/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 1.0708 - val_accuracy: 0.9727\n",
      "Epoch 95/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 1.1100 - val_accuracy: 0.9701\n",
      "Epoch 96/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.9598 - val_accuracy: 0.9742\n",
      "Epoch 97/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 1.0528 - val_accuracy: 0.9727\n",
      "Epoch 98/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 1.1278 - val_accuracy: 0.9731\n",
      "Epoch 99/1000\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.9773 - val_accuracy: 0.9748\n",
      "Epoch 100/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 1.0519 - val_accuracy: 0.9743\n",
      "Epoch 101/1000\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 1.0747 - val_accuracy: 0.9732\n",
      "Epoch 00101: early stopping\n",
      "CPU times: user 6min 24s, sys: 1min 10s, total: 7min 35s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 学習の実施\n",
    "log = model.fit(X_train, Y_train, epochs=1000, batch_size=32, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                         min_delta=0, patience=100,\n",
    "                                                         verbose=1)],\n",
    "         validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフで学習過程を確認\n",
    "plt.plot(log.history['loss'], label='loss')\n",
    "plt.plot(log.history['val_loss'], label='val_loss')\n",
    "plt.legend(frameon=False) \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"crossentropy\")\n",
    "plt.show()\n",
    "\n",
    "# かなり早い段階で過学習を引き起こしていることがわかった（学習データに対しては適合しているが、検証データに対しては全く適合していない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータによる評価\n",
    "\n",
    "# 予測\n",
    "Y_pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー変数の復元\n",
    "Y_test_ = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.96      0.98      0.97      1032\n",
      "           3       0.96      0.97      0.97      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.98      0.97      0.97      1028\n",
      "           8       0.97      0.96      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test_, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この結果は意外だった。というのは、上の図からかなり過学習を起こしていたため、テストデータに対しても適応できないと思ったからだ。\n",
    "# とりあえずacccuracyが0.97であることからまずまずの結果だとは思うが、このモデルではデータの位置関係などを無視してしまっているため、まだ改善の余地がありそう\n",
    "# 次は入力層をCNNにしたモデルで分類をしてみる\n",
    "\n",
    "# (28,28)の画像の形状にreshape\n",
    "X2_train = X_train.reshape(len(X_train), 28, 28, 1)\n",
    "X_test = X_test.reshape(len(X_test), 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 形状を確認\n",
    "print(X2_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X2_train, Y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train= (29400, 10) , X_train= (29400, 28, 28, 1)\n",
      "Y_valid= (12600, 10) , X_valid= (12600, 28, 28, 1)\n",
      "Y_test= (10000, 10) , X_test= (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 形状を確認\n",
    "print(\"Y_train=\", Y_train.shape, \", X_train=\", X_train.shape)\n",
    "print(\"Y_valid=\", Y_valid.shape, \", X_valid=\", X_valid.shape)\n",
    "print(\"Y_test=\", Y_test.shape, \", X_test=\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Conv2D(32, kernel_size=3, padding=\"same\", strides=1,\n",
    "    input_shape=(28, 28, 1,), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "# 中間層\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# 出力層\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                401424    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 402,458\n",
      "Trainable params: 402,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの構造を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.7154 - accuracy: 0.7744 - val_loss: 0.2957 - val_accuracy: 0.9153\n",
      "Epoch 2/5000\n",
      "919/919 [==============================] - 4s 5ms/step - loss: 0.2084 - accuracy: 0.9397 - val_loss: 0.1575 - val_accuracy: 0.9526\n",
      "Epoch 3/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.1191 - accuracy: 0.9664 - val_loss: 0.1186 - val_accuracy: 0.9667\n",
      "Epoch 4/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0848 - accuracy: 0.9757 - val_loss: 0.1092 - val_accuracy: 0.9709\n",
      "Epoch 5/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0660 - accuracy: 0.9814 - val_loss: 0.1151 - val_accuracy: 0.9687\n",
      "Epoch 6/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0535 - accuracy: 0.9846 - val_loss: 0.0920 - val_accuracy: 0.9764\n",
      "Epoch 7/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.0913 - val_accuracy: 0.9770\n",
      "Epoch 8/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.1037 - val_accuracy: 0.9755\n",
      "Epoch 9/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.1173 - val_accuracy: 0.9726\n",
      "Epoch 10/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.1244 - val_accuracy: 0.9740\n",
      "Epoch 11/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1076 - val_accuracy: 0.9787\n",
      "Epoch 12/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.1310 - val_accuracy: 0.9779\n",
      "Epoch 13/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1192 - val_accuracy: 0.9761\n",
      "Epoch 14/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.1419 - val_accuracy: 0.9753\n",
      "Epoch 15/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.1672 - val_accuracy: 0.9721\n",
      "Epoch 16/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1691 - val_accuracy: 0.9762\n",
      "Epoch 17/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.1571 - val_accuracy: 0.9777\n",
      "Epoch 18/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1727 - val_accuracy: 0.9771\n",
      "Epoch 19/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1655 - val_accuracy: 0.9780\n",
      "Epoch 20/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1793 - val_accuracy: 0.9764\n",
      "Epoch 21/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1921 - val_accuracy: 0.9754\n",
      "Epoch 22/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1969 - val_accuracy: 0.9751\n",
      "Epoch 23/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2151 - val_accuracy: 0.9763\n",
      "Epoch 24/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2487 - val_accuracy: 0.9746\n",
      "Epoch 25/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2348 - val_accuracy: 0.9767\n",
      "Epoch 26/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.2360 - val_accuracy: 0.9777\n",
      "Epoch 27/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2473 - val_accuracy: 0.9756\n",
      "Epoch 28/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.2630 - val_accuracy: 0.9767\n",
      "Epoch 29/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.2723 - val_accuracy: 0.9768\n",
      "Epoch 30/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2543 - val_accuracy: 0.9763\n",
      "Epoch 31/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2720 - val_accuracy: 0.9779\n",
      "Epoch 32/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.2496 - val_accuracy: 0.9775\n",
      "Epoch 33/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.2710 - val_accuracy: 0.9777\n",
      "Epoch 34/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3191 - val_accuracy: 0.9756\n",
      "Epoch 35/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3074 - val_accuracy: 0.9760\n",
      "Epoch 36/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.2985 - val_accuracy: 0.9778\n",
      "Epoch 37/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.3921 - val_accuracy: 0.9746\n",
      "Epoch 38/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3074 - val_accuracy: 0.9769\n",
      "Epoch 39/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3298 - val_accuracy: 0.9760\n",
      "Epoch 40/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3802 - val_accuracy: 0.9717\n",
      "Epoch 41/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3353 - val_accuracy: 0.9752\n",
      "Epoch 42/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3858 - val_accuracy: 0.9744\n",
      "Epoch 43/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3387 - val_accuracy: 0.9740\n",
      "Epoch 44/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3661 - val_accuracy: 0.9755\n",
      "Epoch 45/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.3971 - val_accuracy: 0.9743\n",
      "Epoch 46/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3797 - val_accuracy: 0.9776\n",
      "Epoch 47/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3401 - val_accuracy: 0.9776\n",
      "Epoch 48/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3578 - val_accuracy: 0.9766\n",
      "Epoch 49/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3458 - val_accuracy: 0.9775\n",
      "Epoch 50/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3521 - val_accuracy: 0.9775\n",
      "Epoch 51/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4652 - val_accuracy: 0.9758\n",
      "Epoch 52/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4109 - val_accuracy: 0.9770\n",
      "Epoch 53/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 9.7800e-04 - accuracy: 0.9996 - val_loss: 0.3724 - val_accuracy: 0.9760\n",
      "Epoch 54/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 8.8965e-04 - accuracy: 0.9997 - val_loss: 0.4383 - val_accuracy: 0.9733\n",
      "Epoch 55/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4370 - val_accuracy: 0.9768\n",
      "Epoch 56/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4107 - val_accuracy: 0.9770\n",
      "Epoch 57/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.4371 - val_accuracy: 0.9767\n",
      "Epoch 58/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 5.4265e-04 - accuracy: 0.9998 - val_loss: 0.4432 - val_accuracy: 0.9755\n",
      "Epoch 59/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 9.9569e-04 - accuracy: 0.9999 - val_loss: 0.4161 - val_accuracy: 0.9774\n",
      "Epoch 60/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 5.6675e-04 - accuracy: 0.9998 - val_loss: 0.4511 - val_accuracy: 0.9774\n",
      "Epoch 61/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 6.1423e-04 - accuracy: 0.9997 - val_loss: 0.4769 - val_accuracy: 0.9730\n",
      "Epoch 62/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 9.3587e-04 - accuracy: 0.9998 - val_loss: 0.4122 - val_accuracy: 0.9782\n",
      "Epoch 63/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 3.9526e-04 - accuracy: 0.9999 - val_loss: 0.4561 - val_accuracy: 0.9786\n",
      "Epoch 64/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 4.5414e-04 - accuracy: 0.9999 - val_loss: 0.4638 - val_accuracy: 0.9765\n",
      "Epoch 65/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 7.0908e-04 - accuracy: 0.9999 - val_loss: 0.4617 - val_accuracy: 0.9782\n",
      "Epoch 66/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 1.8429e-04 - accuracy: 0.9999 - val_loss: 0.4572 - val_accuracy: 0.9778\n",
      "Epoch 67/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 8.5756e-04 - accuracy: 0.9999 - val_loss: 0.4987 - val_accuracy: 0.9771\n",
      "Epoch 68/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 1.7006e-04 - accuracy: 0.9999 - val_loss: 0.4811 - val_accuracy: 0.9768\n",
      "Epoch 69/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.5004 - val_accuracy: 0.9769\n",
      "Epoch 70/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.5010 - val_accuracy: 0.9771\n",
      "Epoch 71/5000\n",
      "919/919 [==============================] - 5s 5ms/step - loss: 7.0904e-04 - accuracy: 0.9999 - val_loss: 0.5304 - val_accuracy: 0.9765\n",
      "Epoch 72/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 4.6227e-04 - accuracy: 0.9998 - val_loss: 0.4789 - val_accuracy: 0.9765\n",
      "Epoch 73/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 3.5973e-04 - accuracy: 0.9999 - val_loss: 0.5136 - val_accuracy: 0.9769\n",
      "Epoch 74/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 5.4395e-04 - accuracy: 0.9999 - val_loss: 0.4875 - val_accuracy: 0.9788\n",
      "Epoch 75/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 4.8184e-04 - accuracy: 0.9999 - val_loss: 0.6141 - val_accuracy: 0.9740\n",
      "Epoch 76/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 4.4563e-04 - accuracy: 0.9999 - val_loss: 0.4993 - val_accuracy: 0.9776\n",
      "Epoch 77/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 7.3020e-04 - accuracy: 0.9999 - val_loss: 0.4811 - val_accuracy: 0.9782\n",
      "Epoch 78/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 3.6198e-04 - accuracy: 0.9999 - val_loss: 0.5106 - val_accuracy: 0.9787\n",
      "Epoch 79/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 1.9168e-05 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9787\n",
      "Epoch 80/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 2.6912e-05 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.9782\n",
      "Epoch 81/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 3.1707e-04 - accuracy: 0.9999 - val_loss: 0.6039 - val_accuracy: 0.9772\n",
      "Epoch 82/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.5743 - val_accuracy: 0.9749\n",
      "Epoch 83/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 1.3189e-05 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.9771\n",
      "Epoch 84/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 7.2282e-07 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.9765\n",
      "Epoch 85/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 1.4597e-04 - accuracy: 0.9999 - val_loss: 0.6702 - val_accuracy: 0.9763\n",
      "Epoch 86/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 1.2785e-04 - accuracy: 0.9999 - val_loss: 0.5953 - val_accuracy: 0.9773\n",
      "Epoch 87/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 2.8542e-05 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.9774\n",
      "Epoch 88/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 4.0895e-04 - accuracy: 0.9999 - val_loss: 0.5932 - val_accuracy: 0.9779\n",
      "Epoch 89/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 8.8650e-04 - accuracy: 0.9999 - val_loss: 0.5898 - val_accuracy: 0.9773\n",
      "Epoch 90/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 6.9711e-04 - accuracy: 0.9999 - val_loss: 0.6312 - val_accuracy: 0.9774\n",
      "Epoch 91/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 3.9471e-04 - accuracy: 0.9999 - val_loss: 0.5851 - val_accuracy: 0.9783\n",
      "Epoch 92/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.5990 - val_accuracy: 0.9758\n",
      "Epoch 93/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 8.6180e-05 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.9763\n",
      "Epoch 94/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 8.0616e-05 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.9773\n",
      "Epoch 95/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 2.3690e-04 - accuracy: 0.9999 - val_loss: 0.6068 - val_accuracy: 0.9775\n",
      "Epoch 96/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 1.9557e-04 - accuracy: 0.9999 - val_loss: 0.6150 - val_accuracy: 0.9758\n",
      "Epoch 97/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 9.4590e-04 - accuracy: 0.9998 - val_loss: 0.6348 - val_accuracy: 0.9779\n",
      "Epoch 98/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 6.4239e-04 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.9755\n",
      "Epoch 99/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 7.6261e-04 - accuracy: 0.9999 - val_loss: 0.6158 - val_accuracy: 0.9783\n",
      "Epoch 100/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 1.6321e-07 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9778\n",
      "Epoch 101/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 7.7698e-04 - accuracy: 0.9999 - val_loss: 0.7269 - val_accuracy: 0.9780\n",
      "Epoch 102/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.6106 - val_accuracy: 0.9769\n",
      "Epoch 103/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 6.8682e-07 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.9736\n",
      "Epoch 104/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 2.4372e-04 - accuracy: 0.9999 - val_loss: 0.6491 - val_accuracy: 0.9767\n",
      "Epoch 105/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.7228 - val_accuracy: 0.9766\n",
      "Epoch 106/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 7.8973e-05 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.9760\n",
      "Epoch 107/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 2.6247e-07 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.9781\n",
      "Epoch 00107: early stopping\n",
      "CPU times: user 35min 31s, sys: 5min 45s, total: 41min 17s\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 学習の実施\n",
    "log = model.fit(X_train, Y_train, epochs=5000, batch_size=32, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                         min_delta=0, patience=100,\n",
    "                                                         verbose=1)],\n",
    "         validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフ表示\n",
    "plt.plot(log.history['loss'], label='loss')\n",
    "plt.plot(log.history['val_loss'], label='val_loss')\n",
    "plt.legend(frameon=False) \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"crossentropy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータによる評価\n",
    "\n",
    "# 予測\n",
    "Y_pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー変数の復元\n",
    "Y_test_ = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.96      0.97      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.96      0.97       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.98      0.97      0.98      1028\n",
      "           8       0.96      0.98      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test_, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracyが変化しなかったが、crossentropy軸の値とepochs=0付近をみる限り、先ほどよりも若干過学習を抑えることが出来、データの位置関係にロバストであることが実感できた。\n",
    "# また、過学習は、学習データについて詳細すぎるデータを与えてしまっていることが原因と考えられる。\n",
    "# そのため、次の手法を導入する。\n",
    "# 過学習を抑制するために、dropout層（与えるデータ情報を大雑把にするため）と、(max)pooling層（データ圧縮するため）を導入する。\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Conv2D(32, kernel_size=3, padding=\"same\", strides=1,\n",
    "    input_shape=(28, 28, 1,), activation=\"relu\"))\n",
    "# プーリング層\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# ドロップアウト層\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# 出力層\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# モデルの構築\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 16)                100368    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 101,402\n",
      "Trainable params: 101,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの構造を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.6416 - accuracy: 0.7934 - val_loss: 0.2481 - val_accuracy: 0.9274\n",
      "Epoch 2/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.2085 - accuracy: 0.9399 - val_loss: 0.1526 - val_accuracy: 0.9569\n",
      "Epoch 3/5000\n",
      "919/919 [==============================] - 5s 6ms/step - loss: 0.1400 - accuracy: 0.9578 - val_loss: 0.1154 - val_accuracy: 0.9667\n",
      "Epoch 4/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.1150 - accuracy: 0.9664 - val_loss: 0.1185 - val_accuracy: 0.9650\n",
      "Epoch 5/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0964 - accuracy: 0.9711 - val_loss: 0.0968 - val_accuracy: 0.9727\n",
      "Epoch 6/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0878 - accuracy: 0.9736 - val_loss: 0.0879 - val_accuracy: 0.9743\n",
      "Epoch 7/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0853 - val_accuracy: 0.9765\n",
      "Epoch 8/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0712 - accuracy: 0.9787 - val_loss: 0.0914 - val_accuracy: 0.9758\n",
      "Epoch 9/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0644 - accuracy: 0.9805 - val_loss: 0.0957 - val_accuracy: 0.9732\n",
      "Epoch 10/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.0989 - val_accuracy: 0.9730\n",
      "Epoch 11/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0913 - val_accuracy: 0.9765\n",
      "Epoch 12/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0861 - val_accuracy: 0.9771\n",
      "Epoch 13/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0504 - accuracy: 0.9849 - val_loss: 0.0813 - val_accuracy: 0.9796\n",
      "Epoch 14/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0488 - accuracy: 0.9859 - val_loss: 0.0923 - val_accuracy: 0.9775\n",
      "Epoch 15/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0437 - accuracy: 0.9876 - val_loss: 0.0841 - val_accuracy: 0.9803\n",
      "Epoch 16/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.0918 - val_accuracy: 0.9783\n",
      "Epoch 17/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0923 - val_accuracy: 0.9785\n",
      "Epoch 18/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 0.0898 - val_accuracy: 0.9788\n",
      "Epoch 19/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0924 - val_accuracy: 0.9787\n",
      "Epoch 20/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.0953 - val_accuracy: 0.9794\n",
      "Epoch 21/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0920 - val_accuracy: 0.9787\n",
      "Epoch 22/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0356 - accuracy: 0.9900 - val_loss: 0.0932 - val_accuracy: 0.9786\n",
      "Epoch 23/5000\n",
      "919/919 [==============================] - 8s 8ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.1175 - val_accuracy: 0.9772\n",
      "Epoch 24/5000\n",
      "919/919 [==============================] - 8s 8ms/step - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.1052 - val_accuracy: 0.9774\n",
      "Epoch 25/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 0.1117 - val_accuracy: 0.9774\n",
      "Epoch 26/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.1017 - val_accuracy: 0.9796\n",
      "Epoch 27/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.1085 - val_accuracy: 0.9796\n",
      "Epoch 28/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.1034 - val_accuracy: 0.9794\n",
      "Epoch 29/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.1051 - val_accuracy: 0.9787\n",
      "Epoch 30/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.1102 - val_accuracy: 0.9785\n",
      "Epoch 31/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.1171 - val_accuracy: 0.9783\n",
      "Epoch 32/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.1163 - val_accuracy: 0.9775\n",
      "Epoch 33/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.1148 - val_accuracy: 0.9780\n",
      "Epoch 34/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.1179 - val_accuracy: 0.9798\n",
      "Epoch 35/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.1238 - val_accuracy: 0.9785\n",
      "Epoch 36/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.1202 - val_accuracy: 0.9790\n",
      "Epoch 37/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.1262 - val_accuracy: 0.9791\n",
      "Epoch 38/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.1266 - val_accuracy: 0.9775\n",
      "Epoch 39/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.1231 - val_accuracy: 0.9797\n",
      "Epoch 40/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.1213 - val_accuracy: 0.9798\n",
      "Epoch 41/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.1181 - val_accuracy: 0.9792\n",
      "Epoch 42/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.1379 - val_accuracy: 0.9780\n",
      "Epoch 43/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.1346 - val_accuracy: 0.9779\n",
      "Epoch 44/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1306 - val_accuracy: 0.9788\n",
      "Epoch 45/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1277 - val_accuracy: 0.9795\n",
      "Epoch 46/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.1370 - val_accuracy: 0.9781\n",
      "Epoch 47/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.1382 - val_accuracy: 0.9777\n",
      "Epoch 48/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.1351 - val_accuracy: 0.9783\n",
      "Epoch 49/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.1290 - val_accuracy: 0.9798\n",
      "Epoch 50/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.1401 - val_accuracy: 0.9792\n",
      "Epoch 51/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.1375 - val_accuracy: 0.9787\n",
      "Epoch 52/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.1422 - val_accuracy: 0.9792\n",
      "Epoch 53/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1262 - val_accuracy: 0.9789\n",
      "Epoch 54/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.1362 - val_accuracy: 0.9799\n",
      "Epoch 55/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1543 - val_accuracy: 0.9787\n",
      "Epoch 56/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1449 - val_accuracy: 0.9813\n",
      "Epoch 57/5000\n",
      "919/919 [==============================] - 10s 11ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1626 - val_accuracy: 0.9779\n",
      "Epoch 58/5000\n",
      "919/919 [==============================] - 9s 10ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.1470 - val_accuracy: 0.9794\n",
      "Epoch 59/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.1428 - val_accuracy: 0.9787\n",
      "Epoch 60/5000\n",
      "919/919 [==============================] - 11s 12ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.1474 - val_accuracy: 0.9794\n",
      "Epoch 61/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.1495 - val_accuracy: 0.9806\n",
      "Epoch 62/5000\n",
      "919/919 [==============================] - 9s 10ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1552 - val_accuracy: 0.9799\n",
      "Epoch 63/5000\n",
      "919/919 [==============================] - 11s 12ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.1828 - val_accuracy: 0.9791\n",
      "Epoch 64/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1797 - val_accuracy: 0.9775\n",
      "Epoch 65/5000\n",
      "919/919 [==============================] - 8s 9ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.1516 - val_accuracy: 0.9802\n",
      "Epoch 66/5000\n",
      "919/919 [==============================] - 11s 12ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.1638 - val_accuracy: 0.9790\n",
      "Epoch 67/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1667 - val_accuracy: 0.9794\n",
      "Epoch 68/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.1721 - val_accuracy: 0.9783\n",
      "Epoch 69/5000\n",
      "919/919 [==============================] - 9s 10ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1517 - val_accuracy: 0.9781\n",
      "Epoch 70/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.1743 - val_accuracy: 0.9771\n",
      "Epoch 71/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.1583 - val_accuracy: 0.9787\n",
      "Epoch 72/5000\n",
      "919/919 [==============================] - 12s 14ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.1799 - val_accuracy: 0.9772\n",
      "Epoch 73/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.1696 - val_accuracy: 0.9794\n",
      "Epoch 74/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1794 - val_accuracy: 0.9777\n",
      "Epoch 75/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1685 - val_accuracy: 0.9794\n",
      "Epoch 76/5000\n",
      "919/919 [==============================] - 12s 13ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1564 - val_accuracy: 0.9812\n",
      "Epoch 77/5000\n",
      "919/919 [==============================] - 10s 11ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.1723 - val_accuracy: 0.9810\n",
      "Epoch 78/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1636 - val_accuracy: 0.9782\n",
      "Epoch 79/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.1581 - val_accuracy: 0.9795\n",
      "Epoch 80/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.1758 - val_accuracy: 0.9787\n",
      "Epoch 81/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.1797 - val_accuracy: 0.9799\n",
      "Epoch 82/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.1800 - val_accuracy: 0.9790\n",
      "Epoch 83/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.2093 - val_accuracy: 0.9788\n",
      "Epoch 84/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.1774 - val_accuracy: 0.9800\n",
      "Epoch 85/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.1960 - val_accuracy: 0.9796\n",
      "Epoch 86/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.1744 - val_accuracy: 0.9795\n",
      "Epoch 87/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.1879 - val_accuracy: 0.9791\n",
      "Epoch 88/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.1925 - val_accuracy: 0.9796\n",
      "Epoch 89/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 0.1951 - val_accuracy: 0.9790\n",
      "Epoch 90/5000\n",
      "919/919 [==============================] - 6s 6ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.1728 - val_accuracy: 0.9810\n",
      "Epoch 91/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: 0.1780 - val_accuracy: 0.9792\n",
      "Epoch 92/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.1825 - val_accuracy: 0.9790\n",
      "Epoch 93/5000\n",
      "919/919 [==============================] - 9s 10ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.2167 - val_accuracy: 0.9787\n",
      "Epoch 94/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.1816 - val_accuracy: 0.9779\n",
      "Epoch 95/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.1850 - val_accuracy: 0.9790\n",
      "Epoch 96/5000\n",
      "919/919 [==============================] - 8s 8ms/step - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.1852 - val_accuracy: 0.9806\n",
      "Epoch 97/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.1974 - val_accuracy: 0.9806\n",
      "Epoch 98/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.2082 - val_accuracy: 0.9798\n",
      "Epoch 99/5000\n",
      "919/919 [==============================] - 7s 8ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.2006 - val_accuracy: 0.9801\n",
      "Epoch 100/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.1869 - val_accuracy: 0.9794\n",
      "Epoch 101/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.2020 - val_accuracy: 0.9775\n",
      "Epoch 102/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.1849 - val_accuracy: 0.9803\n",
      "Epoch 103/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.1949 - val_accuracy: 0.9781\n",
      "Epoch 104/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.1788 - val_accuracy: 0.9811\n",
      "Epoch 105/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.2044 - val_accuracy: 0.9780\n",
      "Epoch 106/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.2141 - val_accuracy: 0.9779\n",
      "Epoch 107/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.2062 - val_accuracy: 0.9801\n",
      "Epoch 108/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.2036 - val_accuracy: 0.9790\n",
      "Epoch 109/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.2152 - val_accuracy: 0.9776\n",
      "Epoch 110/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.2090 - val_accuracy: 0.9798\n",
      "Epoch 111/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.2062 - val_accuracy: 0.9797\n",
      "Epoch 112/5000\n",
      "919/919 [==============================] - 7s 7ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.1929 - val_accuracy: 0.9804\n",
      "Epoch 113/5000\n",
      "919/919 [==============================] - 6s 7ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.2057 - val_accuracy: 0.9790\n",
      "Epoch 00113: early stopping\n",
      "CPU times: user 44min 25s, sys: 11min 4s, total: 55min 29s\n",
      "Wall time: 13min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 学習の実施\n",
    "log = model.fit(X_train, Y_train, epochs=5000, batch_size=32, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                         min_delta=0, patience=100,\n",
    "                                                         verbose=1)],\n",
    "         validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフ表示\n",
    "plt.plot(log.history['loss'], label='loss')\n",
    "plt.plot(log.history['val_loss'], label='val_loss')\n",
    "plt.legend(frameon=False) \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"crossentropy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータによる評価\n",
    "\n",
    "# 予測\n",
    "Y_pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー変数の復元\n",
    "Y_test_ = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.99      0.97      0.98      1032\n",
      "           3       0.96      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.97      0.98      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.99      0.98      1028\n",
      "           8       0.99      0.96      0.97       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "print(classification_report(Y_test_, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracyも0.98と増加したが、前までのモデルと比べて、過学習具合が小さくなった。\n",
    "\n",
    "# 全体を通して\n",
    "# 大規模データセットだと、情報をある程度落とさなければ容易に過学習をしてしまうということが実感できた。\n",
    "# （初回提出時にはsklearnのdigit datasetを使用し、dropout,poolingを行わなくても極端に過学習をすることはありませんでした。）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
